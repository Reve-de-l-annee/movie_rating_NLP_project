<h3>줄거리를 활용한 영화 관람등급 예측</h3>

- NLP 트랙학습 project

---

<h3>Information</h3>

- 팀원: 이수현, 이채영, 한창헌

**About Project**

1. Introduction


영상물 등급을 평가하는데 오랜 시간이 걸린다.하지만 이 등급은 영화의 수익성과 밀접하게 연관이 되어 있어서 등급이 나온 후 조정을 위해 다시 영화를 찍거나 편집하는 등의 노력이 동반된다. 만약 딥러닝을 활용하여 등급을 예측 할 수 있다면 사전에 많은 조치를 취할 수 있을 것이다. 

프로젝트는 다음과 같은 순서로 진행된다.

- 네이버 영화 사이트로 부터 줄거리와 영상 등급 크롤링 해오기

- koBert 모델에 맞는 데이터 전처리 해주기

- koBert 모델 학습시키기

2.Our Approach

전처리는 영화 줄거리 데이터와 라벨인 등급을 리스트로 매핑하는 것으로 시작된다. 그 후 리스트의 각각의 요소들은 토크나이저를 거쳐 임베딩된다. 이렇게 얻은 토큰화 데이터를 입력값으로 사용하여 사전 학습된 bert에  (768, 4 )크기의 피드 포워드 레이어를 추가해 분류를 수행하였다.

2.1 Data

 네이버 영화 사이트를 크롤링 해서 데이터 프레임에 저장하였다. 10만 개의 데이터를 크롤링 해왔지만 줄거리와 영상물 등급이 모두 있는 영화만을 남기다 보니, 데이터 프레임에는  31743개의 줄거리, 평론가 평점, 네티즌 평점, 제목, 영어 제목, 상영시간, 메이킹 노츠, 영상물 등급 등의 데이터만 남았다. 이 중에서도 다른 컬럼은 쓰지 않고, 우리는 줄거리와, 등급만을 이용한다. 모델에 학습시키기 위해 '청소년 관람불가'를 0으로, '15세 관람가'를 1로, '12세 관람가'를 2, 그리고 '전체 관람가'를 3으로 매핑시켰다.

EDA를 통해, 각각의 관람가에 해당하는 영화 줄거리의 키워드가 두드러지게 다르다는 것을 알게 되었다. 예를 들어서,12세 관람가 영화에는 '마을','마음','세계' 등의 키워드가, 청소년 관람불가 영화에서는 '살인' ,'죽음','섹스' 등의 키워드가 워드 클라우드 결과로 나왔다.

2.2 Embedding

기본 BERT에서는 데이터를 입력하기 전에 3가지 임베딩 레이어를 기반으로 입력 데이터를 임베딩으로 변환해야한다.

- 토큰 임베딩 : 문장을 토큰화하여 토큰들을 추출하고, 문장의 시작에는 [CLS]를 끝에는 [SEP]을 추가한다.

- 세그먼트 임베딩 : 각각의 토큰들이 어떤 문장의 소속인지 구별해주는 임베딩이다.

- 위치 임베딩 : 트랜스포머가 모든 단어를 병렬로 처리하므로 단어 순서에 관한 정보를 제공해주는 임베딩이다.

그 후 워드피스 토크나이저를 이용해서 하위 단어로 분할하며 토큰화를 마무리한다.

2.3 Classification Model

우리는 사전 학습된 bert에 (768, 4 )크기의 피드 포워드 레이어를 추가해서 모델을 만들었다.

BERT는 마스크 언어 모델링 즉 문장내 토큰 중 15%를 마스킹하여 이 단어를 예측하도록 각 레이어를 거치면서 가중치를 업데이트 해 나간다. 분류를 위해서는 마지막 레이어를 거친  [CLS] 토큰의 값을 가져와 소프트 맥스 함수를 사용해 각 클래스별 확률 값을 계산하여 분류를 수행한다. [CLS] 토큰을 사용하는 이유는 encoder layer를 거치면서 나머지 token들의 정보를 바탕으로 representation이 생성되며, 이는 곧 나머지 토큰들의 정보를 담고 있다는 의미이다. 이와 같은 이유로 [CLS] token의 output을 classifier에 넘겨주게 되는 것이다.

---

**Flask**

![Directory Structure](https://user-images.githubusercontent.com/74871527/186577990-47223fd1-350d-45e2-a6f7-72939ab539ae.png)
